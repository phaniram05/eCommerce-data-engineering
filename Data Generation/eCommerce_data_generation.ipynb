{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7344e9c7-e283-4056-aeef-96b837ef889f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\n",
      "Requirement already satisfied: faker in /local_disk0/.ephemeral_nfs/envs/pythonEnv-82e52375-fb39-4724-92ec-f913f2f1f8ee/lib/python3.9/site-packages (36.1.1)\n",
      "Requirement already satisfied: tzdata in /local_disk0/.ephemeral_nfs/envs/pythonEnv-82e52375-fb39-4724-92ec-f913f2f1f8ee/lib/python3.9/site-packages (from faker) (2025.1)\n",
      "Python interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "%pip install faker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "827c3ae7-3738-4d00-baaf-2c85be899ca1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e6a5851-76e9-49ac-8c3c-f8263f05b7cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import uuid\n",
    "import random\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "408c1947-0be8-4c4e-b642-6afc0b8b311e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Generate Products data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2140fe6-f8f0-4d3e-a446-14468f4ab544",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fake = Faker('en_US')\n",
    "Faker.seed(12345)\n",
    "\n",
    "def generate_products(n):\n",
    "    categories = ['Electronics', 'Clothing', 'Home & Garden', 'Books', 'Toys', 'Sports', 'Cosmetics', 'Invalid', 'Automotive', 'Jewelry', 'Food & Beverages', 'Pet Supplies', 'Office Supplies', 'Health & Wellness', 'Music', 'Movies', 'Furniture', 'Outdoor & Camping', 'Art & Crafts', 'Baby Products']\n",
    "    products_df = pd.DataFrame({\n",
    "        'product_id': [uuid.uuid4() for _ in range(n)],\n",
    "        'sku': [fake.unique.ean13() for _ in range(n)],\n",
    "        'product_name': [fake.catch_phrase() for _ in range(n)],\n",
    "        'description': [fake.paragraph() for _ in range(n)],\n",
    "        'category': [fake.random_element(elements=categories) for _ in range(n)],\n",
    "        'brand': [fake.company() for _ in range(n)],\n",
    "        'price': [round(fake.random.uniform(5, 500), 2) for _ in range(n)],\n",
    "        'weight': [round(fake.random.uniform(0.1, 20), 2) for _ in range(n)],\n",
    "        'in_stock': [fake.random.randint(0, 1000) for _ in range(n)],\n",
    "        'is_active': [fake.boolean(chance_of_getting_true=90) for _ in range(n)],\n",
    "        'created_at': [fake.date_time_this_year() for _ in range(n)]\n",
    "    })\n",
    "\n",
    "    products_df.loc[products_df.sample(frac=0.05).index, 'category'] = 'Invalid'  # 5% of categories are invalid\n",
    "    return products_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f3c7673-33e5-4c89-a724-7372401147be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Generate Customers data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14765a50-e6e2-4141-a1c3-bacd82e0dac5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_customers(n):\n",
    "    customers_df = pd.DataFrame({\n",
    "        'customer_id': [uuid.uuid4() for _ in range(n)],\n",
    "        'first_name': [fake.first_name() for _ in range(n)],\n",
    "        'last_name': [fake.last_name() for _ in range(n)],\n",
    "        'email': [fake.email() for _ in range(n)],\n",
    "        'phone_number': [fake.phone_number() for _ in range(n)],\n",
    "        'address': [fake.street_address() for _ in range(n)],\n",
    "        'city': [fake.city() for _ in range(n)],\n",
    "        'state': [fake.state() for _ in range(n)],\n",
    "        'zip_code': [fake.zipcode() for _ in range(n)],\n",
    "        'country': ['United States' for _ in range(n)],\n",
    "        'date_of_birth': [fake.date_of_birth(minimum_age=18, maximum_age=90) for _ in range(n)],\n",
    "        'gender': [fake.random_element(elements=('M', 'F', 'Other')) for _ in range(n)],\n",
    "        'registration_date': [fake.date_time_this_decade() for _ in range(n)],\n",
    "        'last_login': [fake.date_time_this_month() for _ in range(n)]\n",
    "    })\n",
    "    customers_df.loc[customers_df.sample(frac=0.1).index, 'email'] = np.nan  # 10% of emails are missing\n",
    "    customers_df.loc[customers_df.sample(frac=0.05).index, 'zip_code'] = 'INVALID'  # 5% of zip codes are invalid\n",
    "    return customers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "349f43ee-0957-48ce-97cc-823bfef639d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Generate Promotions Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e4f281d-3448-4ba9-a54e-b67d447cbfde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_promotions(n):\n",
    "    start_dates = [fake.date_time_this_year() for _ in range(n)]\n",
    "    promotions_df = pd.DataFrame({\n",
    "        'promotion_id': [uuid.uuid4() for _ in range(n)],\n",
    "        'name': [fake.catch_phrase() for _ in range(n)],\n",
    "        'description': [fake.paragraph() for _ in range(n)],\n",
    "        'discount_type': [fake.random_element(elements=('Percentage', 'Fixed Amount')) for _ in range(n)],\n",
    "        'discount_value': [round(fake.random.uniform(5, 50), 2) for _ in range(n)],\n",
    "        'start_date': start_dates,\n",
    "        'end_date': [fake.date_between(start_date=start_date, end_date=start_date + timedelta(days=30)) for start_date in start_dates]\n",
    "    })\n",
    "    promotions_df.loc[promotions_df.sample(frac=0.1).index, 'discount_value'] = np.nan  # 10% of discount values are missing\n",
    "\n",
    "    return promotions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4aa33c1-1b63-4727-b690-930fa08aacae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Generate Orders Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b0e14d8-6cf7-41b2-b0b9-b37791972dbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_orders(customers, promotions, n):\n",
    "    payment_methods = ['Credit Card', 'Debit Card', 'PayPal', 'Bank Transfer', 'Cash on Delivery','Invalid']\n",
    "    orders_df = pd.DataFrame({\n",
    "        'order_id': [uuid.uuid4() for _ in range(n)],\n",
    "        'customer_id': [fake.random.choice(customers['customer_id']) for _ in range(n)],\n",
    "        'order_date': [fake.date_time_this_year() for _ in range(n)],\n",
    "        'status': [fake.random_element(elements=('Pending', 'Processing', 'Shipped', 'Delivered', 'Cancelled')) for _ in range(n)],\n",
    "        'total_amount': [round(fake.random.uniform(10, 1000), 2) for _ in range(n)],\n",
    "        'promotion_id': [fake.random.choice(promotions['promotion_id']) for _ in range(n)],\n",
    "        'payment_method': [fake.random_element(elements=payment_methods) for _ in range(n)],\n",
    "        'shipping_cost': [round(fake.random.uniform(5, 50), 2) for _ in range(n)]\n",
    "    })\n",
    "    orders_df.loc[orders_df.sample(frac=0.1).index, 'total_amount'] = np.nan  # 10% of total amounts are missing\n",
    "    orders_df.loc[orders_df.sample(frac=0.05).index, 'payment_method'] = 'Invalid'  # 5% of payment methods are invalid\n",
    "    return orders_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f78f984-a04d-424a-9ae6-105bdc2577d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generate data and convert UUID columns to String datatype\n",
    "\n",
    "# Products - 10000 unique products\n",
    "products_df = generate_products(n=10000)\n",
    "products_df['product_id'] = products_df['product_id'].astype(str)\n",
    "\n",
    "# Customers - 1000 unique customers\n",
    "customers_df = generate_customers(n=1000)\n",
    "customers_df['customer_id'] = customers_df['customer_id'].astype(str)\n",
    "\n",
    "# Promotions - 50\n",
    "promotions_df = generate_promotions(n=50)\n",
    "promotions_df['promotion_id'] = promotions_df['promotion_id'].astype(str)\n",
    "\n",
    "# Orders - 30000\n",
    "orders_df = generate_orders(customers_df, promotions_df, n=30000)\n",
    "orders_df['order_id'] = orders_df['order_id'].astype(str)\n",
    "orders_df['customer_id'] = orders_df['customer_id'].astype(str)\n",
    "orders_df['promotion_id'] = orders_df['promotion_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2270195e-597a-400b-86a1-27ad0715df40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Populate shipping information in orders from the randomly selected customer\n",
    "for index, row in orders_df.iterrows():\n",
    "    customer = customers_df[customers_df['customer_id'] == row['customer_id']].iloc[0]\n",
    "    orders_df.at[index, 'shipping_address'] = customer['address']\n",
    "    orders_df.at[index, 'shipping_city'] = customer['city']\n",
    "    orders_df.at[index, 'shipping_state'] = customer['state']\n",
    "    orders_df.at[index, 'shipping_zip'] = customer['zip_code']\n",
    "    orders_df.at[index, 'shipping_country'] = customer['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15192942-0b08-45b7-be57-6cdd59c3ac59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Randomly select a subset of orders (e.g., 20% of the DataFrame)\n",
    "subset = orders_df.sample(frac=0.2, random_state=42)\n",
    "\n",
    "# Update the address information for the selected subset\n",
    "subset['shipping_address'] = subset.apply(lambda _: fake.street_address(), axis=1)\n",
    "subset['shipping_city'] = subset.apply(lambda _: fake.city(), axis=1)\n",
    "subset['shipping_state'] = subset.apply(lambda _: fake.state(), axis=1)\n",
    "subset['shipping_zip'] = subset.apply(lambda _: fake.zipcode(), axis=1)\n",
    "subset['shipping_country'] = subset.apply(lambda _: 'United States', axis=1)\n",
    "\n",
    "# Update the original DataFrame with the modified subset\n",
    "orders_df.update(subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b05cbefe-8b59-4f3b-a964-376e2e8902bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Generate Order Line Items Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6328eb9b-db07-45eb-9d55-a201756d2d59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_order_line_items(orders, products, n):\n",
    "    df = pd.DataFrame({\n",
    "        'line_item_id': [uuid.uuid4() for _ in range(n)],\n",
    "        'order_id': [fake.random.choice(orders['order_id']) for _ in range(n)],\n",
    "        'product_id': [fake.random.choice(products['product_id']) for _ in range(n)],\n",
    "        'quantity': [fake.random.randint(1, 10) for _ in range(n)],\n",
    "        'unit_price': [0 for _ in range(n)],\n",
    "        'subtotal': [0 for _ in range(n)]\n",
    "    })\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2c69160-bc2a-4acd-aac1-fb20003d6730",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generate order line items data\n",
    "\n",
    "order_line_items_df = generate_order_line_items(orders_df, products_df, 60000)\n",
    "\n",
    "for index, row in order_line_items_df.iterrows():\n",
    "        product = products_df[products_df['product_id'] == row['product_id']].iloc[0]\n",
    "        order_line_items_df.at[index, 'unit_price'] = product['price']\n",
    "\n",
    "order_line_items_df['subtotal'] = order_line_items_df['quantity'] * order_line_items_df['unit_price']\n",
    "order_line_items_df.loc[order_line_items_df.sample(frac=0.1).index, 'quantity'] = np.nan  # 10% of quantities are missing\n",
    "order_line_items_df.loc[order_line_items_df.sample(frac=0.1).index, 'unit_price'] = np.nan  # 10% of unit prices are missing\n",
    "\n",
    "\n",
    "order_line_items_df['line_item_id'] = order_line_items_df['line_item_id'].astype(str)\n",
    "order_line_items_df['order_id'] = order_line_items_df['order_id'].astype(str)\n",
    "order_line_items_df['product_id'] = order_line_items_df['product_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d84f227-c894-4fec-92e7-7fb1e108ea7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4f1ce2f-de2d-45d3-bb73-ef32155e6a41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read file from ADLS\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Configure the storage account access key\n",
    "storage_account_name = \"<azure_storage_account_name>\"\n",
    "storage_account_key = \"<azure_storage_account_key>\"\n",
    "container_name = \"<azure_container_name>\"\n",
    "\n",
    "# Set up the Spark configuration\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set(f\"fs.azure.account.key.{storage_account_name}.dfs.core.windows.net\", storage_account_key)\n",
    "\n",
    "# Define the ADLS Gen2 path\n",
    "adls_path = f\"abfss://{container_name}@{storage_account_name}.dfs.core.windows.net/landing/\"\n",
    "\n",
    "\n",
    "products = spark.createDataFrame(products_df)\n",
    "customers = spark.createDataFrame(customers_df)\n",
    "orders = spark.createDataFrame(orders_df)\n",
    "orderLineItems = spark.createDataFrame(order_line_items_df)\n",
    "promotions = spark.createDataFrame(promotions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bd3e116-b3dd-4da2-80b1-40ae00d21078",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "products.coalesce(1).write.format('csv').mode('append').option('header', 'true').save(adls_path + 'products')\n",
    "customers.coalesce(1).write.format('csv').mode('append').option('header', 'true').save(adls_path + 'customers')\n",
    "orders.coalesce(1).write.format('csv').mode('append').option('header', 'true').save(adls_path + 'orders')\n",
    "orderLineItems.coalesce(1).write.format('csv').mode('append').option('header', 'true').save(adls_path + 'orderLineItems')\n",
    "promotions.coalesce(1).write.format('csv').mode('append').option('header', 'true').save(adls_path + 'promotions')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0855e081-8e2d-4da4-8cb1-bf34e5440ad6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Script to download CSV files using a link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3f75ff0-9f9b-4da0-991e-a970b879a9d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# import base64\n",
    "# from IPython.display import HTML\n",
    "\n",
    "# spark = SparkSession.builder.getOrCreate()\n",
    "# # df = spark.read.csv(\"products.csv\", header=True, inferSchema=True)\n",
    "# # pandas_df = df.toPandas()\n",
    "# csv_data = order_line_items_df.to_csv(index=False)\n",
    "# b64 = base64.b64encode(csv_data.encode()).decode()\n",
    "# href = f'<a href=\"data:text/csv;base64,{b64}\" download=\"lineitems.csv\">Click here to download file from DBFS</a>'\n",
    "# HTML(href)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "eCommerce_data_generation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
